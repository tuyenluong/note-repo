Act like a professional QA, write me a set of API test cases that placed in a table of spreadsheet like, it will meet these criteria and apply all these techniques:
-- Criteria --
1. Verify correct HTTP status code. For example, creating a resource should return 201 CREATED and unpermitted requests should return 403 FORBIDDEN, etc.
2. Verify response payload. Check valid JSON body and correct field names, types, and values — including in error responses.
3. Verify response headers. HTTP server headers have implications on both security and performance.
4. Verify correct application state. This is optional and applies mainly to manual testing, or when a UI or another interface can be easily inspected.
5. Verify basic performance sanity. If an operation was completed successfully but took an unreasonable amount of time, the test fails.
-- Techniques --
1. Basic positive tests (happy paths)
	1. All requests should return 2XX HTTP status code  
	2. Returned status code is according to spec:   
		1. 200 OK for GET requests  
		2. 201 for POST or PUT requests creating a new resource   
		3. 200, 202, or 204 for a DELETE operation and so on
	3. Response is a well-formed JSON object
	4. Response structure is according to data model (schema validation: field **names** and field **types** are as expected, including nested objects; field **values** are as expected; non-nullable fields are not null, etc.)
	5. For GET requests, verify there is NO STATE CHANGE in the system (idempotence)
	6. For POST, DELETE, PATCH, PUT operations
		1. Ensure action has been performed correctly in the system by:
		2. Performing appropriate GET request and inspecting response
		3. Refreshing the UI in the web application and verifying new state (only applicable to manual testing)
	7. Verify that HTTP headers are as expected, including `content-type,` `connection`, `cache-control`, `expires`.`access-control-allow-origin`, `keep-alive`, HSTS, and other standard header fields – according to spec.
	8. Verify that information is NOT leaked via headers (e.g. `X-Powered-By` header is not sent to user).
2.  Extended positive testing with optional parameters
	1. Validate status code: As in #1
	2. Verify response structure and content as in #1.
		1. In addition, check the following parameters:  
			1. filter: ensure the response is filtered on the specified value.   
			2. sort: specify field on which to sort, test ascending and descending options. Ensure the response is sorted according to selected field and sort direction.  
			3. skip: ensure the specified number of results from the start of the dataset is skipped  
			4. limit: ensure dataset size is bounded by specified limit.   
			5. limit + skip: Test pagination  
		2. Check combinations of all optional fields (fields + sort + limit + skip) and verify expected response.
	3. Validate state: As in #1
	4. Validate headers: As in #1

Combine all the Expected results in this format: "Status code: Response payload: Application state: Headers:" add 1 more columns that represent Request specifications: "Method: End point: Headers: Params: Body payload:"


Negative testing with valid input

Negative testing with invalid input

Destructive testing

Boundary Value Analysis

Equivalence Class Partitioning

Decision Table Based Testing

